theta <- theta - lr * grad
}
# Track loss at this epoch
probs <- 1 / (1 + exp(-X %*% theta))
if (loss_type == "logistic") {
loss_history[epoch] <- mean(log(1 + exp(-y * (X %*% theta))))
} else if (loss_type == "cross-entropy") {
eps <- 1e-6
loss_history[epoch] <- -mean(y * log(probs + eps) + (1 - y) * log(1 - probs + eps))
}
}
list(theta = theta, loss_history = loss_history)
}
# Convert data to matrices/vectors
X_tree <- as.matrix(tree_data)
y_tree <- as.numeric(tree_labels)
X_animal <- as.matrix(animal_data)
y_animal <- as.numeric(animal_labels)
X_myth <- as.matrix(myth_data)
y_myth <- as.numeric(myth_labels)
# Convert all features and labels properly to matrix and numeric
X_tree <- as.matrix(tree_data)
y_tree <- as.numeric(tree_labels)
X_animal <- as.matrix(animal_data)
y_animal <- as.numeric(animal_labels)
X_myth <- as.matrix(myth_data)
y_myth <- as.numeric(myth_labels)
dim(X_tree)     # Should give [n, 3]  (e.g., 124 3)
length(y_tree)  # Should match n     (e.g., 124)
# Tree models
sgd_tree_logistic <- train_sgd(X_tree, y_tree, loss_type = "logistic")
sgd_tree_entropy  <- train_sgd(X_tree, y_tree, loss_type = "cross-entropy")
# Animal models
sgd_animal_logistic <- train_sgd(X_animal, y_animal, loss_type = "logistic")
sgd_animal_entropy  <- train_sgd(X_animal, y_animal, loss_type = "cross-entropy")
# Mythology models
sgd_myth_logistic <- train_sgd(X_myth, y_myth, loss_type = "logistic")
sgd_myth_entropy  <- train_sgd(X_myth, y_myth, loss_type = "cross-entropy")
library(ggplot2)
plot_loss_curve <- function(model, title) {
loss_df <- data.frame(
Iteration = seq_along(model$loss_history),
Loss = model$loss_history
)
ggplot(loss_df, aes(x = Iteration, y = Loss)) +
geom_line(color = "steelblue", linewidth = 1) +
ggtitle(title) +
theme_minimal()
}
# Tree label loss curves
plot_loss_curve(sgd_tree_logistic, "Tree - Logistic Loss")
plot_loss_curve(sgd_tree_entropy, "Tree - Cross-Entropy Loss")
# Animal label loss curves
plot_loss_curve(sgd_animal_logistic, "Animal - Logistic Loss")
plot_loss_curve(sgd_animal_entropy, "Animal - Cross-Entropy Loss")
# Mythology label loss curves
plot_loss_curve(sgd_myth_logistic, "Mythology - Logistic Loss")
plot_loss_curve(sgd_myth_entropy, "Mythology - Cross-Entropy Loss")
load("../data/features.RData")
head(features_df)
load("../data/features.RData")
head(features_df)
annotation <- read.csv("../data/Annotation.csv", stringsAsFactors = FALSE)
annotation$Tree <- as.numeric(annotation$Tree)
annotation$Animal <- as.numeric(annotation$Animal)
annotation$Mythological <- as.numeric(annotation$Mythological)
merged_df <- merge(features_df, annotation, by.x = "Panel", by.y = "Panel")
head(merged_df)
annotation <- read.csv("../data/Annotation.csv", stringsAsFactors = FALSE)
labels_df <- annotation[, c("Index", "Panel", "Tree", "Animal", "Mythological.Character")]
colnames(labels_df) <- c("Index", "Panel", "Tree_Label", "Animal_Label", "Mythology_Label")
labels_df <- na.omit(labels_df)
head(labels_df)
merged_df <- merge(features_df, labels_df, by = c("Index", "Panel"))
save(merged_df, file = "../data/merged_features_labels.RData")
load("../data/merged_features_labels.RData")
str(merged_df)
tree_data <- merged_df[, c("R_mean", "G_mean", "B_mean")]
tree_labels <- merged_df$Tree_Label
animal_data <- merged_df[, c("R_mean", "G_mean", "B_mean")]
animal_labels <- merged_df$Animal_Label
myth_data <- merged_df[, c("R_mean", "G_mean", "B_mean")]
myth_labels <- merged_df$Mythology_Label
save(tree_data, tree_labels, animal_data, animal_labels, myth_data, myth_labels,
file = "../data/datasets.RData")
# Preview
table(tree_labels)
table(animal_labels)
table(myth_labels)
train_sgd <- function(X, y, loss_type = "logistic", lr = 0.01, epochs = 100) {
n <- nrow(X)
p <- ncol(X)
theta <- rep(0, p)
loss_history <- numeric(epochs)
for (epoch in 1:epochs) {
for (i in 1:n) {
xi <- X[i, , drop = FALSE]
yi <- y[i]
score <- as.numeric(xi %*% theta)
if (loss_type == "logistic") {
grad <- as.numeric(-yi * xi / (1 + exp(yi * score)))
} else if (loss_type == "cross-entropy") {
prob <- 1 / (1 + exp(-score))
grad <- as.numeric((prob - yi) * xi)
}
theta <- theta - lr * grad
}
probs <- 1 / (1 + exp(-X %*% theta))
if (loss_type == "logistic") {
loss_history[epoch] <- mean(log(1 + exp(-y * (X %*% theta))))
} else if (loss_type == "cross-entropy") {
eps <- 1e-6
loss_history[epoch] <- -mean(y * log(probs + eps) + (1 - y) * log(1 - probs + eps))
}
}
list(theta = theta, loss_history = loss_history)
}
X_tree <- as.matrix(tree_data)
y_tree <- as.numeric(tree_labels)
X_animal <- as.matrix(animal_data)
y_animal <- as.numeric(animal_labels)
X_myth <- as.matrix(myth_data)
y_myth <- as.numeric(myth_labels)
X_tree <- as.matrix(tree_data)
y_tree <- as.numeric(tree_labels)
X_animal <- as.matrix(animal_data)
y_animal <- as.numeric(animal_labels)
X_myth <- as.matrix(myth_data)
y_myth <- as.numeric(myth_labels)
dim(X_tree)
length(y_tree)
sgd_tree_logistic <- train_sgd(X_tree, y_tree, loss_type = "logistic")
sgd_tree_entropy  <- train_sgd(X_tree, y_tree, loss_type = "cross-entropy")
sgd_animal_logistic <- train_sgd(X_animal, y_animal, loss_type = "logistic")
sgd_animal_entropy  <- train_sgd(X_animal, y_animal, loss_type = "cross-entropy")
sgd_myth_logistic <- train_sgd(X_myth, y_myth, loss_type = "logistic")
sgd_myth_entropy  <- train_sgd(X_myth, y_myth, loss_type = "cross-entropy")
library(ggplot2)
plot_loss_curve <- function(model, title) {
loss_df <- data.frame(
Iteration = seq_along(model$loss_history),
Loss = model$loss_history
)
ggplot(loss_df, aes(x = Iteration, y = Loss)) +
geom_line(color = "steelblue", linewidth = 1) +
ggtitle(title) +
theme_minimal()
}
plot_loss_curve(sgd_tree_logistic, "Tree - Logistic Loss")
plot_loss_curve(sgd_tree_entropy, "Tree - Cross-Entropy Loss")
plot_loss_curve(sgd_animal_logistic, "Animal - Logistic Loss")
plot_loss_curve(sgd_animal_entropy, "Animal - Cross-Entropy Loss")
plot_loss_curve(sgd_myth_logistic, "Mythology - Logistic Loss")
plot_loss_curve(sgd_myth_entropy, "Mythology - Cross-Entropy Loss")
predict_labels <- function(model, X) {
probs <- 1 / (1 + exp(-X %*% model$theta))
preds <- ifelse(probs >= 0.5, 1, 0)
return(preds)
}
compute_accuracy <- function(y_true, y_pred) {
mean(y_true == y_pred)
}
# Tree
tree_preds_log <- predict_labels(sgd_tree_logistic, X_tree)
tree_preds_entropy <- predict_labels(sgd_tree_entropy, X_tree)
cat("Tree Accuracy (Logistic):", compute_accuracy(y_tree, tree_preds_log), "\n")
cat("Tree Accuracy (Cross-Entropy):", compute_accuracy(y_tree, tree_preds_entropy), "\n")
# Animal
animal_preds_log <- predict_labels(sgd_animal_logistic, X_animal)
animal_preds_entropy <- predict_labels(sgd_animal_entropy, X_animal)
cat("Animal Accuracy (Logistic):", compute_accuracy(y_animal, animal_preds_log), "\n")
cat("Animal Accuracy (Cross-Entropy):", compute_accuracy(y_animal, animal_preds_entropy), "\n")
# Mythology
myth_preds_log <- predict_labels(sgd_myth_logistic, X_myth)
myth_preds_entropy <- predict_labels(sgd_myth_entropy, X_myth)
cat("Mythology Accuracy (Logistic):", compute_accuracy(y_myth, myth_preds_log), "\n")
cat("Mythology Accuracy (Cross-Entropy):", compute_accuracy(y_myth, myth_preds_entropy), "\n")
save(sgd_tree_logistic, sgd_tree_entropy,
sgd_animal_logistic, sgd_animal_entropy,
sgd_myth_logistic, sgd_myth_entropy,
file = "../data/sgd_models.RData")
# Load data from Project 1
load("../data/datasets.RData")
# Check one example
str(tree_data)
length(tree_labels)
load("../data/datasets.RData")
str(tree_data)
length(tree_labels)
install.packages("optimx")
library(optimx)
# Define logistic loss
compute_loss <- function(X, y, theta, loss_type) {
scores <- X %*% theta
probs <- 1 / (1 + exp(-scores))
eps <- 1e-6
if (loss_type == "logistic") {
return(mean(log(1 + exp(-y * scores))))
} else if (loss_type == "cross-entropy") {
return(-mean(y * log(probs + eps) + (1 - y) * log(1 - probs + eps)))
}
}
# Define the training function
train_optimx <- function(X, y, method = "BFGS", loss_type = "logistic") {
X <- as.matrix(X)
y <- as.numeric(y)
theta_init <- rep(0, ncol(X))
# Loss function for optimizer
loss_fn <- function(theta) {
compute_loss(X, y, theta, loss_type)
}
result <- optimx(par = theta_init, fn = loss_fn, method = method)
return(result)
}
result_bfgs <- train_optimx(tree_data, tree_labels, method = "BFGS", loss_type = "logistic")
print(result_bfgs)
methods <- c("BFGS", "L-BFGS-B", "CG", "Nelder-Mead")
results_tree <- lapply(methods, function(m) {
cat("Training Tree label with", m, "...\n")
train_optimx(tree_data, tree_labels, method = m, loss_type = "logistic")
})
names(results_tree) <- methods
sapply(results_tree, function(res) res$value)
# Compare final loss values from each optimizer
final_losses <- sapply(results_tree, function(res) res$value)
print(final_losses)
run_optim_with_tracking <- function(X, y, method = "BFGS", loss_type = "logistic") {
X <- as.matrix(X)
y <- as.numeric(y)
theta <- rep(0, ncol(X))
loss_values <- numeric(100)
for (i in 1:100) {
res <- optimx::optimx(par = theta, fn = function(th) compute_loss(X, y, th, loss_type),
method = method, control = list(maxit = 1))
theta <- as.numeric(res[1, 1:ncol(X)])  # update theta
loss_values[i] <- res$value
}
return(loss_values)
}
# Example for BFGS
loss_bfgs <- run_optim_with_tracking(tree_data, tree_labels, method = "BFGS")
plot(loss_bfgs, type = "l", col = "blue", lwd = 2,
main = "Loss Curve - BFGS", xlab = "Iteration", ylab = "Loss")
# Combine results
summary_df <- data.frame(
Method = names(results_tree),
Final_Loss = sapply(results_tree, function(res) res$value)
)
print(summary_df)
run_optim_with_tracking <- function(X, y, method = "BFGS", loss_type = "logistic", steps = 100) {
X <- as.matrix(X)
y <- as.numeric(y)
theta <- rep(0, ncol(X))
loss_values <- numeric(steps)
for (i in 1:steps) {
res <- optimx::optimx(
par = theta,
fn = function(th) compute_loss(X, y, th, loss_type),
method = method,
control = list(maxit = 1)
)
theta <- as.numeric(res[1, 1:ncol(X)])
loss_values[i] <- res$value
}
return(loss_values)
}
loss_bfgs        <- run_optim_with_tracking(tree_data, tree_labels, method = "BFGS")
loss_lbfgsb      <- run_optim_with_tracking(tree_data, tree_labels, method = "L-BFGS-B")
loss_cg          <- run_optim_with_tracking(tree_data, tree_labels, method = "CG")
loss_neldermead  <- run_optim_with_tracking(tree_data, tree_labels, method = "Nelder-Mead")
plot(loss_bfgs, type = "l", col = "blue", lwd = 2,
xlab = "Iteration", ylab = "Loss", main = "Optimizer Loss Comparison", ylim = range(c(loss_bfgs, loss_lbfgsb, loss_cg, loss_neldermead)))
lines(loss_lbfgsb, col = "red", lwd = 2)
lines(loss_cg, col = "green", lwd = 2)
lines(loss_neldermead, col = "purple", lwd = 2)
legend("topright", legend = c("BFGS", "L-BFGS-B", "CG", "Nelder-Mead"),
col = c("blue", "red", "green", "purple"), lwd = 2)
loss_bfgs_animal       <- run_optim_with_tracking(animal_data, animal_labels, method = "BFGS")
loss_lbfgsb_animal     <- run_optim_with_tracking(animal_data, animal_labels, method = "L-BFGS-B")
loss_cg_animal         <- run_optim_with_tracking(animal_data, animal_labels, method = "CG")
loss_neldermead_animal <- run_optim_with_tracking(animal_data, animal_labels, method = "Nelder-Mead")
plot(loss_bfgs_animal, type = "l", col = "blue", lwd = 2,
xlab = "Iteration", ylab = "Loss", main = "Animal - Optimizer Loss Comparison",
ylim = range(c(loss_bfgs_animal, loss_lbfgsb_animal, loss_cg_animal, loss_neldermead_animal)))
lines(loss_lbfgsb_animal, col = "red", lwd = 2)
lines(loss_cg_animal, col = "green", lwd = 2)
lines(loss_neldermead_animal, col = "purple", lwd = 2)
legend("topright", legend = c("BFGS", "L-BFGS-B", "CG", "Nelder-Mead"),
col = c("blue", "red", "green", "purple"), lwd = 2)
loss_bfgs_myth       <- run_optim_with_tracking(myth_data, myth_labels, method = "BFGS")
loss_lbfgsb_myth     <- run_optim_with_tracking(myth_data, myth_labels, method = "L-BFGS-B")
loss_cg_myth         <- run_optim_with_tracking(myth_data, myth_labels, method = "CG")
loss_neldermead_myth <- run_optim_with_tracking(myth_data, myth_labels, method = "Nelder-Mead")
plot(loss_bfgs_myth, type = "l", col = "blue", lwd = 2,
xlab = "Iteration", ylab = "Loss", main = "Mythology - Optimizer Loss Comparison",
ylim = range(c(loss_bfgs_myth, loss_lbfgsb_myth, loss_cg_myth, loss_neldermead_myth)))
lines(loss_lbfgsb_myth, col = "red", lwd = 2)
lines(loss_cg_myth, col = "green", lwd = 2)
lines(loss_neldermead_myth, col = "purple", lwd = 2)
legend("topright", legend = c("BFGS", "L-BFGS-B", "CG", "Nelder-Mead"),
col = c("blue", "red", "green", "purple"), lwd = 2)
loss_bfgs_animal       <- run_optim_with_tracking(animal_data, animal_labels, method = "BFGS")
loss_lbfgsb_animal     <- run_optim_with_tracking(animal_data, animal_labels, method = "L-BFGS-B")
loss_cg_animal         <- run_optim_with_tracking(animal_data, animal_labels, method = "CG")
loss_neldermead_animal <- run_optim_with_tracking(animal_data, animal_labels, method = "Nelder-Mead")
plot(loss_bfgs_animal, type = "l", col = "blue", lwd = 2,
xlab = "Iteration", ylab = "Loss", main = "Animal - Optimizer Loss Comparison",
ylim = range(c(loss_bfgs_animal, loss_lbfgsb_animal, loss_cg_animal, loss_neldermead_animal)))
lines(loss_lbfgsb_animal, col = "red", lwd = 2)
lines(loss_cg_animal, col = "green", lwd = 2)
lines(loss_neldermead_animal, col = "purple", lwd = 2)
legend("topright", legend = c("BFGS", "L-BFGS-B", "CG", "Nelder-Mead"),
col = c("blue", "red", "green", "purple"), lwd = 2)
predict_from_theta <- function(X, theta) {
probs <- 1 / (1 + exp(-X %*% theta))
preds <- ifelse(probs >= 0.5, 1, 0)
return(preds)
}
compute_accuracy <- function(y_true, y_pred) {
mean(y_true == y_pred)
}
theta_bfgs_tree <- attr(loss_bfgs_tree, "theta")
# Compute predictions
predict_logistic <- function(theta, X) {
probs <- 1 / (1 + exp(-X %*% theta))
as.numeric(probs > 0.5)
}
# Tree
pred_bfgs_tree <- predict_logistic(theta_bfgs_tree, X_tree)
compute_loss <- function(X, y, theta, loss_type) {
scores <- X %*% theta
probs <- 1 / (1 + exp(-scores))
eps <- 1e-6
if (loss_type == "logistic") {
return(mean(log(1 + exp(-y * scores))))
} else if (loss_type == "cross-entropy") {
return(-mean(y * log(probs + eps) + (1 - y) * log(1 - probs + eps)))
}
}
train_optimx <- function(X, y, method = "BFGS", loss_type = "logistic") {
X <- as.matrix(X)
y <- as.numeric(y)
theta_init <- rep(0, ncol(X))
loss_fn <- function(theta) {
compute_loss(X, y, theta, loss_type)
}
result <- optimx::optimx(par = theta_init, fn = loss_fn, method = method)
attr(result, "theta") <- coef(result)
return(result)
}
# Rerun to get the object
loss_bfgs_tree <- train_optimx(tree_data, tree_labels, method = "BFGS", loss_type = "logistic")
theta_bfgs_tree <- attr(loss_bfgs_tree, "theta")
# Compute predictions
predict_logistic <- function(theta, X) {
probs <- 1 / (1 + exp(-X %*% theta))
as.numeric(probs > 0.5)
}
# Tree
pred_bfgs_tree <- predict_logistic(theta_bfgs_tree, X_tree)
# ------------------------------
# Loss Function
compute_loss <- function(X, y, theta, loss_type) {
scores <- X %*% theta
probs <- 1 / (1 + exp(-scores))
eps <- 1e-6
if (loss_type == "logistic") {
return(mean(log(1 + exp(-y * scores))))
} else if (loss_type == "cross-entropy") {
return(-mean(y * log(probs + eps) + (1 - y) * log(1 - probs + eps)))
}
}
# ------------------------------
# Optimizer Wrapper
train_optimx <- function(X, y, method = "BFGS", loss_type = "logistic") {
X <- as.matrix(X)
y <- as.numeric(y)
theta_init <- rep(0, ncol(X))
loss_fn <- function(theta) {
compute_loss(X, y, theta, loss_type)
}
result <- optimx::optimx(par = theta_init, fn = loss_fn, method = method)
return(list(theta = coef(result), loss = result$value))
}
# ------------------------------
# Prediction Function
predict_logistic <- function(theta, X) {
probs <- 1 / (1 + exp(-X %*% theta))
as.numeric(probs > 0.5)
}
# ------------------------------
# Accuracy Function
compute_accuracy <- function(y_true, y_pred) {
mean(y_true == y_pred)
}
X_tree <- as.matrix(tree_data)
y_tree <- as.numeric(tree_labels)
X_animal <- as.matrix(animal_data)
y_animal <- as.numeric(animal_labels)
X_myth <- as.matrix(myth_data)
y_myth <- as.numeric(myth_labels)
# Tree
loss_bfgs_tree <- train_optimx(X_tree, y_tree, method = "BFGS")
loss_lbfgsb_tree <- train_optimx(X_tree, y_tree, method = "L-BFGS-B")
loss_cg_tree <- train_optimx(X_tree, y_tree, method = "CG")
loss_nm_tree <- train_optimx(X_tree, y_tree, method = "Nelder-Mead")
# Animal
loss_bfgs_animal <- train_optimx(X_animal, y_animal, method = "BFGS")
loss_lbfgsb_animal <- train_optimx(X_animal, y_animal, method = "L-BFGS-B")
loss_cg_animal <- train_optimx(X_animal, y_animal, method = "CG")
loss_nm_animal <- train_optimx(X_animal, y_animal, method = "Nelder-Mead")
# Mythology
loss_bfgs_myth <- train_optimx(X_myth, y_myth, method = "BFGS")
loss_lbfgsb_myth <- train_optimx(X_myth, y_myth, method = "L-BFGS-B")
loss_cg_myth <- train_optimx(X_myth, y_myth, method = "CG")
loss_nm_myth <- train_optimx(X_myth, y_myth, method = "Nelder-Mead")
accuracy_summary <- data.frame(
Optimizer = c("BFGS", "L-BFGS-B", "CG", "Nelder-Mead"),
Tree = c(
compute_accuracy(y_tree, predict_logistic(loss_bfgs_tree$theta, X_tree)),
compute_accuracy(y_tree, predict_logistic(loss_lbfgsb_tree$theta, X_tree)),
compute_accuracy(y_tree, predict_logistic(loss_cg_tree$theta, X_tree)),
compute_accuracy(y_tree, predict_logistic(loss_nm_tree$theta, X_tree))
),
Animal = c(
compute_accuracy(y_animal, predict_logistic(loss_bfgs_animal$theta, X_animal)),
compute_accuracy(y_animal, predict_logistic(loss_lbfgsb_animal$theta, X_animal)),
compute_accuracy(y_animal, predict_logistic(loss_cg_animal$theta, X_animal)),
compute_accuracy(y_animal, predict_logistic(loss_nm_animal$theta, X_animal))
),
Mythology = c(
compute_accuracy(y_myth, predict_logistic(loss_bfgs_myth$theta, X_myth)),
compute_accuracy(y_myth, predict_logistic(loss_lbfgsb_myth$theta, X_myth)),
compute_accuracy(y_myth, predict_logistic(loss_cg_myth$theta, X_myth)),
compute_accuracy(y_myth, predict_logistic(loss_nm_myth$theta, X_myth))
)
)
# Bonus: Visualize Accuracy Comparison Across Labels
library(ggplot2)
# Reshape the accuracy_summary dataframe to long format for ggplot
library(tidyr)
accuracy_long <- pivot_longer(
accuracy_summary,
cols = c("Tree", "Animal", "Mythology"),
names_to = "Label",
values_to = "Accuracy"
)
# Reuse or redefine prediction + accuracy helper
compute_accuracy <- function(y_true, y_pred) {
mean(y_true == y_pred)
}
predict_logistic <- function(theta, X) {
probs <- 1 / (1 + exp(-X %*% theta))
as.numeric(probs > 0.5)
}
# Predictions for all optimizers
pred_bfgs_tree <- predict_logistic(theta_bfgs_tree, X_tree)
# --- Bonus: Extend to all labels (Tree, Animal, Mythology) ---
# Training helper
train_all_optimx <- function(data, labels, loss_type = "logistic") {
methods <- c("BFGS", "L-BFGS-B", "CG", "Nelder-Mead")
names(methods) <- methods
lapply(methods, function(m) train_optimx(data, labels, method = m, loss_type = loss_type))
}
# Train
results_tree      <- train_all_optimx(tree_data, tree_labels)
results_animal    <- train_all_optimx(animal_data, animal_labels)
results_mythology <- train_all_optimx(myth_data, mythology_labels)
# --- Bonus: Extend to all labels (Tree, Animal, Mythology) ---
# Training helper
train_all_optimx <- function(data, labels, loss_type = "logistic") {
methods <- c("BFGS", "L-BFGS-B", "CG", "Nelder-Mead")
names(methods) <- methods
lapply(methods, function(m) train_optimx(data, labels, method = m, loss_type = loss_type))
}
# Train
results_tree      <- train_all_optimx(tree_data, tree_labels)
results_animal    <- train_all_optimx(animal_data, animal_labels)
results_mythology <- train_all_optimx(myth_data, mythology_labels)
# --- Bonus: Extend to all labels (Tree, Animal, Mythology) ---
# Training helper
train_all_optimx <- function(data, labels, loss_type = "logistic") {
methods <- c("BFGS", "L-BFGS-B", "CG", "Nelder-Mead")
names(methods) <- methods
lapply(methods, function(m) train_optimx(data, labels, method = m, loss_type = loss_type))
}
# Train
results_tree      <- train_all_optimx(tree_data, tree_labels)
results_animal    <- train_all_optimx(animal_data, animal_labels)
results_mythology <- train_all_optimx(myth_data, mythology.labels)
# --- Bonus: Extend to all labels (Tree, Animal, Mythology) ---
# Training helper
train_all_optimx <- function(data, labels, loss_type = "logistic") {
methods <- c("BFGS", "L-BFGS-B", "CG", "Nelder-Mead")
names(methods) <- methods
lapply(methods, function(m) train_optimx(data, labels, method = m, loss_type = loss_type))
}
# Train
results_tree      <- train_all_optimx(tree_data, tree_labels)
results_animal    <- train_all_optimx(animal_data, animal_labels)
results_mythology <- train_all_optimx(myth_data, mythology labels)
# --- Bonus: Extend to all labels (Tree, Animal, Mythology) ---
# Training helper
train_all_optimx <- function(data, labels, loss_type = "logistic") {
methods <- c("BFGS", "L-BFGS-B", "CG", "Nelder-Mead")
names(methods) <- methods
lapply(methods, function(m) train_optimx(data, labels, method = m, loss_type = loss_type))
}
# Train
results_tree      <- train_all_optimx(tree_data, tree_labels)
results_animal    <- train_all_optimx(animal_data, animal_labels)
results_mythology <- train_all_optimx(myth_data, mythology_label)
